{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca719d13",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb64244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import sagemaker\n",
    "import boto3\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import botocore\n",
    "from botocore.config import Config\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tabulate import tabulate\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead1e78",
   "metadata": {},
   "source": [
    "### Identify resources created by CloudFormation stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962223c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cf_client = boto3.client('cloudformation')\n",
    "cf_client_response = cf_client.describe_stacks(StackName='invoice-recognize')\n",
    "s3_bucket_name = None\n",
    "comprehend_role_arn = None\n",
    "lambda_arn = None\n",
    "\n",
    "for output in cf_client_response[\"Stacks\"][0][\"Outputs\"]:\n",
    "    \n",
    "    if output[\"OutputKey\"] == \"S3BucketName\":\n",
    "        s3_bucket_name = output[\"OutputValue\"]\n",
    "        \n",
    "    if output[\"OutputKey\"] == \"ComprehendRoleArn\":\n",
    "        comprehend_role_arn = output[\"OutputValue\"]\n",
    "        \n",
    "    if output[\"OutputKey\"] == \"ComprehendRoleArn\":\n",
    "        comprehend_role_arn = output[\"OutputValue\"]\n",
    "        \n",
    "    if output[\"OutputKey\"] == \"LambdaFunctionArn\":\n",
    "        lambda_arn = output[\"OutputValue\"]\n",
    "        \n",
    "print ('Bucket name: {}'.format(s3_bucket_name))\n",
    "print ('Comprehend role arn: {}'.format(comprehend_role_arn))\n",
    "print ('Lambda function arn: {}'.format(lambda_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eae0664",
   "metadata": {},
   "source": [
    "# Create custom entity recognizer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1435ffe",
   "metadata": {},
   "source": [
    "### Copy hotel invoices for training the entity recognizer model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd3966",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "for file in tqdm(glob.glob(\"./dataset/*/*.pdf\" ), desc=\"Copy hotel invoices to S3\"):\n",
    "        \n",
    "    s3_client.upload_file(file, s3_bucket_name, \"/\".join(file.split('/')[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27349b9d",
   "metadata": {},
   "source": [
    "### Extract text from hotel invoices (created for model train) by using Amazon Textract. Copy extracted text to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c4727",
   "metadata": {},
   "source": [
    "Extract text from pdf hotel invoices step takes 45-50 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e8fc5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set retry mode\n",
    "config = Config(\n",
    "            retries = {\n",
    "                      'max_attempts': 5,\n",
    "                      'mode': 'standard'\n",
    "            }\n",
    ")\n",
    "\n",
    "textract = boto3.client('textract', config=config)\n",
    "\n",
    "# Create output directory for extracted hotel invoices\n",
    "output_path = './extracted_text/train'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    \n",
    "  os.makedirs(output_path)\n",
    "  print (\"{} directory created\".format(output_path))\n",
    "    \n",
    "\n",
    "for file in tqdm([os.path.basename(x) for x in glob.glob(\"./dataset/train/*.pdf\")], desc=\"Processing hotel invoices\"):\n",
    "\n",
    "    # Start hotel invoice text detection\n",
    "    response = textract.start_document_text_detection(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': s3_bucket_name,\n",
    "                'Name': 'dataset/train/{}'.format(file)\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Get JobId for text detection process\n",
    "    jobId = response['JobId']\n",
    "    \n",
    "    # Wait will text detection process completed\n",
    "    status = None \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        response = textract.get_document_text_detection(JobId=jobId)\n",
    "        status = response[\"JobStatus\"]\n",
    " \n",
    "        if status != \"IN_PROGRESS\":\n",
    "            break\n",
    "        \n",
    "    if status == 'SUCCEEDED':\n",
    "        \n",
    "        extracted_file_name = file.split('/')[-1].replace('pdf','txt')\n",
    "        extracted_file_name_path = \"./{}/{}\".format(output_path, extracted_file_name)\n",
    "\n",
    "        # Save extracted text file locally\n",
    "        with open(extracted_file_name_path, \"w\") as extracted_file: \n",
    "            for item in response[\"Blocks\"]:\n",
    "                if item[\"BlockType\"] == \"LINE\":\n",
    "                    extracted_file.write(item[\"Text\"]+' ')\n",
    "                    \n",
    "                    \n",
    "        # Copy extracted text file to S3\n",
    "        s3_client.upload_file(extracted_file_name_path, s3_bucket_name, 'extracted_text/train/{}'.format(extracted_file_name))\n",
    "        \n",
    "        print (\"File {} extracted and copied to S3\".format(file))\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30deab44",
   "metadata": {},
   "source": [
    "### Create Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b95b03",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Read guest_entity_list.csv\n",
    "entities = {}\n",
    "with open(\"dataset/guest_entity_list.csv\", \"r\") as f:\n",
    "    for num, line in enumerate(f.readlines()):\n",
    "        entity=line.split(',')\n",
    "        entities[entity[1].strip()] = entity[0]\n",
    "\n",
    "if not os.path.exists('annotation'):\n",
    "    \n",
    "  os.makedirs('annotation')\n",
    "    \n",
    "with open(\"./annotation/annotations.csv\", \"w\", encoding=\"utf-8\") as csv_file:\n",
    "    \n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"File\", \"Line\", \"Begin Offset\", \"End Offset\", \"Type\"])\n",
    "    \n",
    "    for file_path in glob.glob(\"./extracted_text/train/*\"):\n",
    "        file_name = os.path.basename(file_path)\n",
    "  \n",
    "        with open(file_path, \"r\") as fr:\n",
    "            for num, line in enumerate(fr.readlines()):\n",
    "                search=re.search(entities[file_name.split('.')[0]], line)\n",
    "                if search:\n",
    "                    csv_writer.writerow([file_name, num, search.start(), search.end(), \"HOTEL_GUEST\"])\n",
    "\n",
    "\n",
    "s3_client.upload_file(\"./annotation/annotations.csv\", s3_bucket_name, 'annotation/annotations.csv')\n",
    "print ('Annotation file created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f5d91",
   "metadata": {},
   "source": [
    "The annotation file uses an guest entity list that was prepared beforehand to label the location where the guest name appears in the text. \n",
    "\n",
    "Below is how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c173f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "annotation = pd.read_csv('annotation/annotations.csv')\n",
    "annotation.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef70dc7",
   "metadata": {},
   "source": [
    "### Create the entity recognizer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335aa8d",
   "metadata": {},
   "source": [
    "We can then use the annotation file along with the training dataset to train a custom entity recognition model in Comprehend.\n",
    "\n",
    "Creation of the entity recognition model takes 20-30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ffc02",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "comprehend_client = boto3.client('comprehend')\n",
    "\n",
    "recognizer_name = 'invoice-recognizer-{}'.format(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "# Submit entity recognition \n",
    "create_entity_recognizer_response = comprehend_client.create_entity_recognizer(\n",
    "    RecognizerName = recognizer_name,\n",
    "    DataAccessRoleArn=comprehend_role_arn,\n",
    "    InputDataConfig={\n",
    "        'EntityTypes': [\n",
    "            {\n",
    "                'Type': 'HOTEL_GUEST'\n",
    "            },\n",
    "        ],\n",
    "        'Documents': {\n",
    "            'S3Uri': 's3://{}/extracted_text/train/'.format(s3_bucket_name),\n",
    "            'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "        },\n",
    "        'Annotations': {\n",
    "            'S3Uri': 's3://{}/annotation/annotations.csv'.format(s3_bucket_name)\n",
    "        }\n",
    "    },\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Wait till model traning completed\n",
    "status = describe_entity_recognizer_response = None\n",
    "while status != 'TRAINED':\n",
    "    \n",
    "    describe_entity_recognizer_response = comprehend_client.describe_entity_recognizer(\n",
    "        EntityRecognizerArn=create_entity_recognizer_response['EntityRecognizerArn']\n",
    "    )\n",
    "    \n",
    "    status = describe_entity_recognizer_response['EntityRecognizerProperties']['Status']\n",
    "    print('Training Job Status:\\t', status)\n",
    "    if status == 'IN_ERROR':\n",
    "        print ('ERROR: ', describe_entity_recognizer_response['EntityRecognizerProperties']['Message'])\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)\n",
    "    \n",
    "model_arn = describe_entity_recognizer_response['EntityRecognizerProperties']['EntityRecognizerArn']\n",
    "print ('Entity recognizer model arn: {}'.format(model_arn))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdaf52",
   "metadata": {},
   "source": [
    "Print model evaluation statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f9c23",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "RecognizerMetadata = describe_entity_recognizer_response['EntityRecognizerProperties']['RecognizerMetadata']\n",
    "EvaluationMetrics = describe_entity_recognizer_response['EntityRecognizerProperties']['RecognizerMetadata']['EvaluationMetrics']\n",
    "\n",
    "table_context = tabulate([[\"Number Of Trained Documents\", \"Number Of Test Documents\"],\n",
    "                          [RecognizerMetadata['NumberOfTrainedDocuments'], RecognizerMetadata['NumberOfTestDocuments']]],\n",
    "                          tablefmt='html'\n",
    ")\n",
    "\n",
    "display(HTML(table_context))\n",
    "\n",
    "\n",
    "table_context = tabulate([[\"Precision\", \"Recall\", \"F1 Score\"], [EvaluationMetrics['Precision'], EvaluationMetrics['Recall'], EvaluationMetrics['F1Score']]],\n",
    "                         tablefmt='html'\n",
    ")\n",
    "                           \n",
    "display(HTML(table_context))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83b728",
   "metadata": {},
   "source": [
    "# Test trained hotel invoice recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa09b8d",
   "metadata": {},
   "source": [
    "## Test trained hotel invoice recognition model in batch mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa054bd",
   "metadata": {},
   "source": [
    "### Extract text from hotel invoices (created for model test) by using Amazon Textract. Copy extracted text to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e9dc16",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set retry mode\n",
    "config = Config(\n",
    "            retries = {\n",
    "                      'max_attempts': 5,\n",
    "                      'mode': 'standard'\n",
    "            }\n",
    ")\n",
    "\n",
    "textract = boto3.client('textract', config=config)\n",
    "\n",
    "output_path = './extracted_text/test'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    \n",
    "  os.makedirs(output_path)\n",
    "  print (\"{} directory created\".format(output_path))\n",
    "    \n",
    "for file in tqdm([os.path.basename(x) for x in glob.glob(\"./dataset/test/*.pdf\")], desc=\"Processing hotel invoices\"):\n",
    "        \n",
    "    # Start hotel invoice text detection\n",
    "    response = textract.start_document_text_detection(\n",
    "        DocumentLocation={\n",
    "            'S3Object': {\n",
    "                'Bucket': s3_bucket_name,\n",
    "                'Name': 'dataset/test/{}'.format(file)\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Get JobId for text detection process\n",
    "    jobId = response['JobId']\n",
    "    \n",
    "    # Wait will text detection process completed\n",
    "    status = None \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        response = textract.get_document_text_detection(JobId=jobId)\n",
    "        status = response[\"JobStatus\"]\n",
    " \n",
    "        if status != \"IN_PROGRESS\":\n",
    "            break\n",
    "        \n",
    "    if status == 'SUCCEEDED':\n",
    "        \n",
    "        extracted_file_name = file.split('/')[-1].replace('pdf','txt')\n",
    "        extracted_file_name_path = \"./{}/{}\".format(output_path, extracted_file_name)\n",
    "\n",
    "        # Save extracted text file locally\n",
    "        with open(extracted_file_name_path, \"w\") as extracted_file: \n",
    "            for item in response[\"Blocks\"]:\n",
    "                if item[\"BlockType\"] == \"LINE\":\n",
    "                    extracted_file.write(item[\"Text\"]+' ')\n",
    "                    \n",
    "                    \n",
    "        # Copy extracted text file to S3\n",
    "        s3_client.upload_file(extracted_file_name_path, s3_bucket_name, 'extracted_text/test/{}'.format(extracted_file_name))\n",
    "        print (\"File {} extracted and copied to S3\".format(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d911fa",
   "metadata": {},
   "source": [
    "### Start hotel invoice recognition job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fdd82",
   "metadata": {},
   "source": [
    "Hotel invoice recognition job takes 20-30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04d30d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "jobname = 'invoice-job-{}'.format(datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\"))\n",
    "\n",
    "start_entities_detection_job_response = comprehend_client.start_entities_detection_job(\n",
    "    JobName = jobname,\n",
    "    InputDataConfig={\n",
    "         'S3Uri': 's3://{}/extracted_text/test'.format(s3_bucket_name),\n",
    "         'InputFormat': 'ONE_DOC_PER_FILE',\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': 's3://{}/batch-detection/output'.format(s3_bucket_name)\n",
    "    },\n",
    "    DataAccessRoleArn=comprehend_role_arn,\n",
    "    EntityRecognizerArn=model_arn,\n",
    "    LanguageCode='en'\n",
    "    \n",
    ")\n",
    "\n",
    "# Wait till batch job is completed\n",
    "status = describe_entity_recognizer_response = None\n",
    "while status != 'COMPLETED':\n",
    "    \n",
    "    describe_entity_recognizer_response = comprehend_client.describe_entities_detection_job(\n",
    "        JobId = start_entities_detection_job_response['JobId']\n",
    "    )\n",
    "    \n",
    "    status = describe_entity_recognizer_response['EntitiesDetectionJobProperties']['JobStatus']\n",
    "    print('Detection Job Status:\\t', status)\n",
    "    if status == 'FAILED':\n",
    "        print ('ERROR: ', describe_entity_recognizer_response['EntitiesDetectionJobProperties']['Message'])\n",
    "        break\n",
    "    \n",
    "    time.sleep(10)\n",
    "    \n",
    "# Retrieve the s3 location of the output\n",
    "detection_job_output_path = describe_entity_recognizer_response['EntitiesDetectionJobProperties']['OutputDataConfig']['S3Uri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8313f4",
   "metadata": {},
   "source": [
    "### Retrieve and check the batch job result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89d3544",
   "metadata": {},
   "source": [
    "Download the output from the batch job and look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8416c573",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!aws s3 cp $detection_job_output_path output.tar.gz\n",
    "!tar -xf output.tar.gz\n",
    "\n",
    "with open('output', 'r') as text:\n",
    "    textfile = text.read()\n",
    "    print(textfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df09aeb2",
   "metadata": {},
   "source": [
    "## Test trained hotel invoice recognition model in real time mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4374d",
   "metadata": {},
   "source": [
    "### Create Comprehend endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85687782",
   "metadata": {},
   "source": [
    "Comprehend endpoint creation step takes 10-15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6246977",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_endpoint_response = comprehend_client.create_endpoint(\n",
    "    EndpointName='invoice-detect-endpoint',\n",
    "    ModelArn=model_arn,\n",
    "    DesiredInferenceUnits=1,\n",
    "    Tags=[\n",
    "        {\n",
    "            'Key': 'Project',\n",
    "            'Value': 'Hotel invoice recognition'\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Wait endpoint creation completed\n",
    "status = describe_endpoint_response = None\n",
    "endpoint_arn = create_endpoint_response['EndpointArn']\n",
    "while status != 'IN_SERVICE':\n",
    "    \n",
    "    describe_endpoint_response = comprehend_client.describe_endpoint(\n",
    "        EndpointArn=endpoint_arn\n",
    "    )\n",
    "    \n",
    "    status = describe_endpoint_response['EndpointProperties']['Status']\n",
    "    print('Endpoint creation Status:\\t', status)\n",
    "    if status == 'FAILED':\n",
    "        print ('ERROR: ', describe_endpoint_response['EndpointProperties']['Status'])\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a53c28d",
   "metadata": {},
   "source": [
    "### Add Lambda function trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35930d",
   "metadata": {},
   "source": [
    "Lambda function will be trigged for a new S3 object event (in our case, hotel invoices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc6843",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "bucket_notification = boto3.resource('s3').BucketNotification(s3_bucket_name)\n",
    "response = bucket_notification.put(\n",
    "    NotificationConfiguration={'LambdaFunctionConfigurations': [{\n",
    "        'LambdaFunctionArn': lambda_arn,\n",
    "        'Events': [\n",
    "                    's3:ObjectCreated:*'\n",
    "        ],\n",
    "        'Filter' : {\n",
    "            'Key' : {\n",
    "                'FilterRules' : [{\n",
    "                    'Name' : 'prefix', 'Value' : 'realtime-detection/invoice'}, {\n",
    "                    'Name' : 'suffix', 'Value' : '.pdf'}\n",
    "                ]}}\n",
    "    },\n",
    "]})\n",
    "\n",
    "print ('Lambda function trigger created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c9c2a",
   "metadata": {},
   "source": [
    "### Start hotel invoice recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67583e8e",
   "metadata": {},
   "source": [
    "Copy hotel invoices for testing into S3 bucket. After S3 object copied, that will trigger Lambda function, which start hotel invoice recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3cd7c",
   "metadata": {},
   "source": [
    "By default, AWS account has the soft limit with one StartDocumentTextDetection job per second. If more that one StartDocumentTextDetection job per second triggered, then throttle error will be raised.\n",
    "For mitigation, we used 10 second delay between each runs. In real production environment, request Amazon Textract\n",
    "quota increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabebd2c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for file_path in tqdm(glob.glob(\"./dataset/test/*.pdf\" ), desc=\"Copy hotel invoices to S3\"):\n",
    "        \n",
    "    \n",
    "    s3_client.upload_file(file_path, s3_bucket_name, 'realtime-detection/invoice/{}'.format(os.path.basename(file_path)))\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f006d",
   "metadata": {},
   "source": [
    "Check recognition results in the invoice-recognize-output DynamoDB table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8d358",
   "metadata": {},
   "source": [
    "# Cleanup resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e95d54",
   "metadata": {},
   "source": [
    "Delete Comprehend endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47de48",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "delete_endpoint_response = comprehend_client.delete_endpoint(\n",
    "    EndpointArn=endpoint_arn\n",
    ")\n",
    "\n",
    "# Wait endpoint deletetion\n",
    "status = describe_endpoint_response = None\n",
    "endpoint_arn = create_endpoint_response['EndpointArn']\n",
    "while True:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        describe_endpoint_response = comprehend_client.describe_endpoint(\n",
    "            EndpointArn=endpoint_arn\n",
    "        )\n",
    "    except botocore.exceptions.ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'ResourceNotFoundException': \n",
    "            print('Endpoint deletion Status:\\t', 'DELETED')\n",
    "            break\n",
    "        else:\n",
    "            raise\n",
    "        \n",
    "    status = describe_endpoint_response['EndpointProperties']['Status']\n",
    "    print('Endpoint deletion Status:\\t', status)\n",
    "    if status == 'FAILED':\n",
    "        print ('ERROR: ', describe_endpoint_response['EndpointProperties']['Status'])\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efdf359",
   "metadata": {},
   "source": [
    "Delete trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552667ec",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "delete_entity_recognizer_response = comprehend_client.delete_entity_recognizer(\n",
    "    EntityRecognizerArn=model_arn\n",
    ")\n",
    "\n",
    "# Wait trained model deletetion\n",
    "status = describe_entity_recognizer_response = None\n",
    "while True:\n",
    "    \n",
    "    try:\n",
    "        describe_entity_recognizer_response = comprehend_client.describe_entity_recognizer(\n",
    "            EntityRecognizerArn=model_arn\n",
    "        )\n",
    "    except botocore.exceptions.ClientError as error:\n",
    "        if error.response['Error']['Code'] == 'ResourceNotFoundException': \n",
    "            print('Deletion Trained Model Status:\\t', 'DELETED')\n",
    "            break\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    status = describe_entity_recognizer_response['EntityRecognizerProperties']['Status']\n",
    "    print('Deletion Trained Model Status:\\t', status)\n",
    "    if status == 'IN_ERROR':\n",
    "        print ('ERROR: ', describe_entity_recognizer_response['EntityRecognizerProperties']['Message'])\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chainer_p36",
   "language": "python",
   "name": "conda_chainer_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}